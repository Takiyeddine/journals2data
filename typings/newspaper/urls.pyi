"""
This type stub file was generated by pyright.
"""

"""
Newspaper treats urls for news articles as critical components.
Hence, we have an entire module dedicated to them.
"""
__title__ = ...
__author__ = ...
__license__ = ...
__copyright__ = ...
log = ...
MAX_FILE_MEMO = ...
_STRICT_DATE_REGEX_PREFIX = ...
DATE_REGEX = ...
STRICT_DATE_REGEX = ...
ALLOWED_TYPES = ...
GOOD_PATHS = ...
BAD_CHUNKS = ...
BAD_DOMAINS = ...
def remove_args(url, keep_params=..., frags=...): # -> str:
    """
    Remove all param arguments from a url.
    """
    ...

def redirect_back(url, source_domain): # -> str:
    """
    Some sites like Pinterest have api's that cause news
    args to direct to their site with the real news url as a
    GET param. This method catches that and returns our param.
    """
    ...

def prepare_url(url, source_url=...): # -> str:
    """
    Operations that purify a url, removes arguments,
    redirects, and merges relatives with absolutes.
    """
    ...

def valid_url(url, verbose=..., test=...): # -> bool:
    """
    Is this URL a valid news-article url?

    Perform a regex check on an absolute url.

    First, perform a few basic checks like making sure the format of the url
    is right, (scheme, domain, tld).

    Second, make sure that the url isn't some static resource, check the
    file type.

    Then, search of a YYYY/MM/DD pattern in the url. News sites
    love to use this pattern, this is a very safe bet.

    Separators can be [\.-/_]. Years can be 2 or 4 digits, must
    have proper digits 1900-2099. Months and days can be
    ambiguous 2 digit numbers, one is even optional, some sites are
    liberal with their formatting also matches snippets of GET
    queries with keywords inside them. ex: asdf.php?topic_id=blahlbah
    We permit alphanumeric, _ and -.

    Our next check makes sure that a keyword is within one of the
    separators in a url (subdomain or early path separator).
    cnn.com/story/blah-blah-blah would pass due to "story".

    We filter out articles in this stage by aggressively checking to
    see if any resemblance of the source& domain's name or tld is
    present within the article title. If it is, that's bad. It must
    be a company link, like 'cnn is hiring new interns'.

    We also filter out articles with a subdomain or first degree path
    on a registered bad keyword.
    """
    ...

def url_to_filetype(abs_url): # -> str | None:
    """
    Input a URL and output the filetype of the file
    specified by the url. Returns None for no filetype.
    'http://blahblah/images/car.jpg' -> 'jpg'
    'http://yahoo.com'               -> None
    """
    ...

def get_domain(abs_url, **kwargs): # -> str | None:
    """
    returns a url's domain, this method exists to
    encapsulate all url code into this file
    """
    ...

def get_scheme(abs_url, **kwargs): # -> str | None:
    """
    """
    ...

def get_path(abs_url, **kwargs): # -> str | None:
    """
    """
    ...

def is_abs_url(url): # -> bool:
    """
    this regex was brought to you by django!
    """
    ...

